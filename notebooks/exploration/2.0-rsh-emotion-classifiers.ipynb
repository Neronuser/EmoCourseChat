{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Emotion classification experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the moment when you get another follower and you cheer . \n",
      "be the greatest dancer of your life !  practice daily positive habits .    \n",
      "if ur heart hurts all the time for tht person something is not right where ' s the\n",
      "i feel awful ,  and it ' s way too freaking early .  now off to leadership highschool .  .  . \n",
      "so chuffed for safc fans !  bet me dar comes in mortz from the match\n",
      "soooo dooowwwn !  !  move on ,  get some sleep .  .  .  me deserve better .   \n",
      " \" we are sorry ,  but the clip you selected is not available from your location .  please select another clip .  \"  no i refuse . \n",
      "my heart and soul  _ babebee is leaving me and i can not even see here\n",
      "chips and curry sauce\n",
      "soo if i hit youu  ,  i garrentee i will not stopp  .  type to keep going till i make a bitch bleed foreal  ! \n",
      "oh and off to work till midnight  -  .  - \n",
      " bahahahaha so many things i could say .  .  .  rt  :  i just shit my pants .  pure  * number *  %  gravy . \n",
      "51 morning  :  )  oh what a bad episode to come in towards the end .  .  .  and only  * number *  more episode ?  ? \n",
      "there is no concrete equation for joy .  you can not explain how to get in your life . \n",
      "i do not need present ' s of king ' s but just just to be in the presence of the king  \n",
      "all my battles r surely handled properly  &  never by me  .  .  .  it feels so good\n",
      "bringing my cousin  &  his friend to jingle jam  &  they get to see drake  &  i dontt  ?  \n",
      "nobody up worth talking too so back to sleep i try to go ! \n",
      "even if you are bad  @  something ,  i cant knock you if you try .   * number *  /  * number *  the time ,  those ppl are the 1s that love it the most .  do not kill their\n",
      "i just absolutely lost my mind .  .   :  ( \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "import re\n",
    "import textacy\n",
    "from textacy.text_utils import detect_language\n",
    "from textacy.preprocess import preprocess_text\n",
    "\n",
    "import os\n",
    "os.chdir('../../')\n",
    "\n",
    "EMOJI_PATTERN = re.compile(\n",
    "    u\"(\\ud83d[\\ude00-\\ude4f])|\"  # emoticons\n",
    "    u\"(\\ud83c[\\udf00-\\uffff])|\"  # symbols & pictographs (1 of 2)\n",
    "    u\"(\\ud83d[\\u0000-\\uddff])|\"  # symbols & pictographs (2 of 2)\n",
    "    u\"(\\ud83d[\\ude80-\\udeff])|\"  # transport & map symbols\n",
    "    u\"(\\ud83c[\\udde0-\\uddff])\"  # flags (iOS)\n",
    "    \"+\", flags=re.UNICODE)\n",
    "MENTIONS_PATTERN = re.compile(u\"@[a-z]+\")\n",
    "HASHTAGS_PATTERN = re.compile(u\"#[a-z]+\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = preprocess_text(text, fix_unicode=True, lowercase=True, no_urls=True, \n",
    "                    no_emails=True, no_phone_numbers=True, no_numbers=True,\n",
    "                    no_currency_symbols=True, no_contractions=True,\n",
    "                    no_accents=True)\n",
    "    no_mentions_text = re.sub(MENTIONS_PATTERN, u\"\", new_text)\n",
    "    no_hashtags_text = re.sub(HASHTAGS_PATTERN, u\"\", no_mentions_text)\n",
    "    no_emojis_text = re.sub(EMOJI_PATTERN, u\"\", no_hashtags_text)\n",
    "    separated_punctuation_text = no_emojis_text.translate(\n",
    "        str.maketrans({key: \" {0} \".format(key) for key in string.punctuation}))\n",
    "    return separated_punctuation_text\n",
    "    \n",
    "\n",
    "EMOTION_DATAPATH = 'data/processed/emotions_full.csv'\n",
    "raw_data = []\n",
    "with open(EMOTION_DATAPATH) as data_file:\n",
    "    reader = csv.reader(data_file, quoting=csv.QUOTE_MINIMAL)\n",
    "    reader.__next__()\n",
    "    for line in reader:\n",
    "        preprocessed_line = preprocess(line[1])\n",
    "        if detect_language(preprocessed_line) == 'en':\n",
    "            doc = textacy.Doc(preprocessed_line, lang='en_core_web_lg')\n",
    "            raw_data.append((doc, line[2]))\n",
    "        \n",
    "for data in raw_data[:20]:\n",
    "    print(data[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "texts, labels = zip(*raw_data)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(texts, encoded_labels, shuffle=True, stratify=encoded_labels, \n",
    "                     random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_vectors = np.array([x.spacy_doc.vector for x in x_train])\n",
    "x_test_vectors = np.array([x.spacy_doc.vector for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectors = [text.to_bag_of_words() for text in x_train]\n",
    "x_test_vectors = [text.to_bag_of_words() for text in x_test]\n",
    "vectorizer = textacy.Vectorizer(weighting='tfidf', normalize=True, smooth_idf=True,\n",
    "min_df=1, max_df=1., max_n_terms=100000)\n",
    "x_train_vectors = vectorizer.fit_transform(x_train_vectors)\n",
    "x_test_vectors = vectorizer.transform(x_test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build testing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "MODELS_TEST_RESULTS = 'reports/tune_test_scores.csv'\n",
    "\n",
    "\n",
    "def hypertune(x, y, model, parameters):\n",
    "    model_obj = model()\n",
    "    clf = GridSearchCV(model_obj, parameters, scoring='f1_micro', \n",
    "                       n_jobs=-1, cv=10, verbose=1)\n",
    "    clf.fit(x, y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def try_model(x, y, model, parameters, name):\n",
    "    print(\"----Started tuning : \" + name + \"----\")\n",
    "    tune_result = hypertune(x, y, model, parameters)\n",
    "    y_pred = tune_result.best_estimator_.predict(x_test_vectors)\n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                                labels=range(len(label_encoder.classes_)), \n",
    "                                target_names=label_encoder.classes_))\n",
    "    test_score = tune_result.score(x_test_vectors, y_test)\n",
    "    print(\"Testing f1_micro: \" + str(test_score))\n",
    "    save = 'models/' + name + '_emotion.pkl'\n",
    "    joblib.dump(tune_result.best_estimator_, save)\n",
    "    print(\"Saved best estimator to \" + save)\n",
    "    with open(MODELS_TEST_RESULTS, \"a\") as test_scores_table:\n",
    "        writer = csv.writer(test_scores_table, quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow([name, test_score, save, str(tune_result.best_params_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "              'n_estimators': [1000],\n",
    "              'max_depth': [None],\n",
    "              'class_weight': [None],\n",
    "              'min_samples_split': [2]}\n",
    "\n",
    "try_model(x_train_vectors, y_train, RandomForestClassifier,\n",
    "          parameters, 'RF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "try_model(x_train_vectors, y_train, SVC, \n",
    "          parameters, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "parameters = {'objective': ['multi:softmax'],\n",
    "              'n_estimators': [50, 100, 500, 1000],\n",
    "              'max_depth': [0, 2, 5, 10],\n",
    "              'colsample_bytree': [0.2, 0.6, 0.8],\n",
    "              'gamma': [0.1, 0.3, 0.5, 0.9]}\n",
    "try_model(x_train_vectors, y_train, xgb.XGBClassifier,\n",
    "          parameters, 'XGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = [{'multi_class': ['ovr'],\n",
    "               'penalty': ['l1', 'l2']\n",
    "             'C': [0.1, 0.5, 0.9, 1.],\n",
    "             'class_weight': [None, 'balanced']},\n",
    "             {'multi_class': ['multinomial'],\n",
    "              'solver': ['lbfgs']\n",
    "             'C': [0.1, 0.5, 0.9, 1.],\n",
    "             'class_weight': [None, 'balanced']}]\n",
    "try_model(x_train_vectors, y_train, LogisticRegression, \n",
    "          parameters, 'LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Started tuning : LR-idf----\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      anger       0.44      0.42      0.43      2157\n",
      "  happiness       0.53      0.70      0.60      2810\n",
      "       love       0.64      0.59      0.61      1555\n",
      "    neutral       0.43      0.30      0.36      1679\n",
      "    sadness       0.46      0.40      0.43      1927\n",
      "\n",
      "avg / total       0.50      0.50      0.49     10128\n",
      "\n",
      "Testing f1_micro: 0.502764612954\n",
      "Saved best estimator to models/LR-idf_emotion.pkl\n",
      "Classification report full data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      anger       0.44      0.42      0.43      2157\n",
      "  happiness       0.53      0.70      0.60      2810\n",
      "       love       0.64      0.59      0.61      1555\n",
      "    neutral       0.43      0.30      0.36      1679\n",
      "    sadness       0.46      0.40      0.43      1927\n",
      "\n",
      "avg / total       0.50      0.50      0.49     10128\n",
      "\n",
      "Testing f1_micro full data: 0.502764612954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = [{'multi_class': ['ovr'],\n",
    "               'penalty': ['l1', 'l2'],\n",
    "             'C': [0.1, 0.5, 0.9, 1.]},\n",
    "             {'multi_class': ['multinomial'],\n",
    "              'solver': ['lbfgs'],\n",
    "             'C': [0.1, 0.5, 0.9, 1.]}]\n",
    "try_model(x_train_vectors, y_train, LogisticRegression, \n",
    "          parameters, 'LR-idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.254239026704\n",
      "  (0, 1)\t0.166102034462\n",
      "  (0, 2)\t0.309069475657\n",
      "  (0, 3)\t0.266305655528\n",
      "  (0, 4)\t0.351406771388\n",
      "  (0, 5)\t0.199882920765\n",
      "  (0, 6)\t0.0836146295847\n",
      "  (0, 7)\t0.126423577371\n",
      "  (0, 8)\t0.308263845653\n",
      "  (0, 9)\t0.146155809548\n",
      "  (0, 10)\t0.33412349698\n",
      "  (0, 11)\t0.104674221814\n",
      "  (0, 12)\t0.552182534244\n",
      "  (0, 13)\t0.105008980761\n"
     ]
    }
   ],
   "source": [
    "print(x_train_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Started tuning : DT----\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 17.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      anger       0.35      0.27      0.30      2157\n",
      "  happiness       0.36      0.72      0.48      2810\n",
      "       love       0.56      0.39      0.46      1555\n",
      "    neutral       0.27      0.19      0.22      1679\n",
      "    sadness       0.49      0.14      0.22      1927\n",
      "\n",
      "avg / total       0.40      0.38      0.35     10128\n",
      "\n",
      "Testing f1_micro: 0.375493680885\n",
      "Saved best estimator to models/DT_emotion.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [None, 2, 5, 10],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'min_samples_split': [2, 3, 5]}\n",
    "try_model(x_train_vectors, y_train, DecisionTreeClassifier, \n",
    "          parameters, 'DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
