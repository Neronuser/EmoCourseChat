{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Emotion classification experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinks that  had a great 50th birthday party  :  ) \nthe moment when you get another follower and you cheer . \nbe the greatest dancer of your life !  practice daily positive habits .    \nif ur heart hurts all the time for tht person something is not right where ' s the\ni feel awful ,  and it ' s way too freaking early .  now off to leadership highschool .  .  . \nso chuffed for safc fans !  bet me dar comes in mortz from the match\nmaking art and viewing art are different at their core ! \nsoooo dooowwwn !  !  move on ,  get some sleep .  .  .  me deserve better .   \n \" we are sorry ,  but the clip you selected is not available from your location .  please select another clip .  \"  no i refuse . \npeople know they can pull you down and they dont give a care  & \nmy heart and soul  _ babebee is leaving me and i can not even see here\nchips and curry sauce\nsoo if i hit youu  ,  i garrentee i will not stopp  .  type to keep going till i make a bitch bleed foreal  ! \noh and off to work till midnight  -  .  - \ni have a package at the post office .  can not think what could be in it .  i do not remember internet shopping while drinking . \n bahahahaha so many things i could say .  .  .  rt  :  i just shit my pants .  pure  * number *  %  gravy . \n51 morning  :  )  oh what a bad episode to come in towards the end .  .  .  and only  * number *  more episode ?  ? \nlarge crowds of manic football fans  &  mascots\nthere is no concrete equation for joy .  you can not explain how to get in your life . \ni do not need present ' s of king ' s but just just to be in the presence of the king  \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "import re\n",
    "import textacy\n",
    "from textacy.text_utils import detect_language\n",
    "from textacy.preprocess import preprocess_text\n",
    "\n",
    "EMOJI_PATTERN = re.compile(\n",
    "    u\"(\\ud83d[\\ude00-\\ude4f])|\"  # emoticons\n",
    "    u\"(\\ud83c[\\udf00-\\uffff])|\"  # symbols & pictographs (1 of 2)\n",
    "    u\"(\\ud83d[\\u0000-\\uddff])|\"  # symbols & pictographs (2 of 2)\n",
    "    u\"(\\ud83d[\\ude80-\\udeff])|\"  # transport & map symbols\n",
    "    u\"(\\ud83c[\\udde0-\\uddff])\"  # flags (iOS)\n",
    "    \"+\", flags=re.UNICODE)\n",
    "MENTIONS_PATTERN = re.compile(u\"@[a-z]+\")\n",
    "HASHTAGS_PATTERN = re.compile(u\"#[a-z]+\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = preprocess_text(text, fix_unicode=True, lowercase=True, no_urls=True, \n",
    "                    no_emails=True, no_phone_numbers=True, no_numbers=True,\n",
    "                    no_currency_symbols=True, no_contractions=True,\n",
    "                    no_accents=True)\n",
    "    no_mentions_text = re.sub(MENTIONS_PATTERN, u\"\", new_text)\n",
    "    no_hashtags_text = re.sub(HASHTAGS_PATTERN, u\"\", no_mentions_text)\n",
    "    no_emojis_text = re.sub(EMOJI_PATTERN, u\"\", no_hashtags_text)\n",
    "    separated_punctuation_text = no_emojis_text.translate(\n",
    "        str.maketrans({key: \" {0} \".format(key) for key in string.punctuation}))\n",
    "    return separated_punctuation_text\n",
    "    \n",
    "\n",
    "EMOTION_DATAPATH = 'data/processed/emotions_full.csv'\n",
    "raw_data = []\n",
    "with open(EMOTION_DATAPATH) as data_file:\n",
    "    reader = csv.reader(data_file, quoting=csv.QUOTE_MINIMAL)\n",
    "    reader.__next__()\n",
    "    for line in reader:\n",
    "        preprocessed_line = preprocess(line[1])\n",
    "        if detect_language(preprocessed_line) == 'en':\n",
    "            doc = textacy.Doc(preprocessed_line, lang='en_core_web_lg')\n",
    "            raw_data.append((doc, line[2]))\n",
    "        \n",
    "for data in raw_data[:20]:\n",
    "    print(data[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "texts, labels = zip(*raw_data)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(texts, encoded_labels, shuffle=True, stratify=encoded_labels, \n",
    "                     random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_vectors = np.array([x.spacy_doc.vector for x in x_train])\n",
    "x_test_vectors = np.array([x.spacy_doc.vector for x in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build testing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Started tuning : RF----\nFitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/PycharmProjects/EmoryChat/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   23.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n             precision    recall  f1-score   support\n\n      anger       0.00      0.00      0.00       482\n       fear       0.60      0.00      0.01       682\n  happiness       0.30      0.62      0.40      2810\n       love       0.32      0.47      0.38      1555\n    neutral       0.21      0.26      0.23      1679\n    sadness       0.22      0.16      0.18      1927\n   surprise       0.14      0.01      0.02      1067\n      worry       0.25      0.02      0.04      1675\n\navg / total       0.26      0.28      0.22     11877\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/PycharmProjects/EmoryChat/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing f1_micro: 0.275827229098\nSaved best estimator to models/RF_emotion.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "MODELS_TEST_RESULTS = 'reports/tune_test_scores.csv'\n",
    "\n",
    "\n",
    "def hypertune(x, y, model, parameters):\n",
    "    model_obj = model()\n",
    "    clf = GridSearchCV(model_obj, parameters, scoring='f1_micro', \n",
    "                       n_jobs=-1, cv=10, verbose=1)\n",
    "    clf.fit(x, y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def try_model(x, y, model, parameters, name):\n",
    "    print(\"----Started tuning : \" + name + \"----\")\n",
    "    tune_result = hypertune(x, y, model, parameters)\n",
    "    y_pred = tune_result.best_estimator_.predict(x_test_vectors)\n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                                labels=range(len(label_encoder.classes_)), \n",
    "                                target_names=label_encoder.classes_))\n",
    "    test_score = tune_result.score(x_test_vectors, y_test)\n",
    "    print(\"Testing f1_micro: \" + str(test_score))\n",
    "    save = 'models/' + name + '_emotion.pkl'\n",
    "    joblib.dump(tune_result.best_estimator_, save)\n",
    "    print(\"Saved best estimator to \" + save)\n",
    "    with open(MODELS_TEST_RESULTS, \"a\") as test_scores_table:\n",
    "        writer = csv.writer(test_scores_table, quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow([name, test_score, save, str(tune_result.best_params_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "              'n_estimators': [10, 100, 1000, 2000],\n",
    "              'max_depth': [None, 2, 5, 10],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'min_samples_split': [2, 3, 5]}\n",
    "\n",
    "try_model(x_train_vectors, y_train, RandomForestClassifier,\n",
    "          parameters, 'RF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Started tuning : SVM----\nFitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/PycharmProjects/EmoryChat/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n             precision    recall  f1-score   support\n\n      anger       0.22      0.01      0.03       482\n       fear       0.33      0.12      0.17       682\n  happiness       0.30      0.53      0.38      2810\n       love       0.34      0.35      0.35      1555\n    neutral       0.20      0.24      0.22      1679\n    sadness       0.20      0.25      0.22      1927\n   surprise       0.13      0.03      0.05      1067\n      worry       0.22      0.04      0.07      1675\n\navg / total       0.25      0.26      0.23     11877\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing f1_micro: 0.262440010104\nSaved best estimator to models/SVM_emotion.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "try_model(x_train_vectors, y_train, SVC, \n",
    "          parameters, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Started tuning : XGB----\nFitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/PycharmProjects/EmoryChat/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   16.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n             precision    recall  f1-score   support\n\n      anger       0.16      0.02      0.03       482\n       fear       0.14      0.06      0.09       682\n  happiness       0.30      0.40      0.35      2810\n       love       0.26      0.36      0.30      1555\n    neutral       0.22      0.24      0.23      1679\n    sadness       0.20      0.17      0.18      1927\n   surprise       0.12      0.12      0.12      1067\n      worry       0.17      0.11      0.13      1675\n\navg / total       0.22      0.23      0.22     11877\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing f1_micro: 0.233981645197\nSaved best estimator to models/XGB_emotion.pkl\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "parameters = {'objective': ['multi:softmax'],\n",
    "              'n_estimators': [50, 100, 500, 1000],\n",
    "              'max_depth': [0, 2, 5, 10],\n",
    "              'colsample_bytree': [0.2, 0.6, 0.8],\n",
    "              'gamma': [0.1, 0.3, 0.5, 0.9]}\n",
    "try_model(x_train_vectors, y_train, xgb.XGBClassifier,\n",
    "          parameters, 'XGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from itertools import product\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "FASTTEXT_INPUT_FILE = 'data/processed/fasttext_input.txt'\n",
    "MODEL_PATH = 'models/fasttext/model'\n",
    "label_prefix = '__label__'\n",
    "with open(FASTTEXT_INPUT_FILE, 'w') as input_file:\n",
    "    for x, y in zip(x_train, y_train):\n",
    "        input_file.write(' , '.join([label_prefix + str(y), x.text]) + '\\n')\n",
    "\n",
    "tested_dims = [10, 100, 300]\n",
    "tested_lrs = [0.1, 0.01, 0.001]\n",
    "combinations = product(tested_dims, tested_lrs)\n",
    "\n",
    "epoch = 5\n",
    "min_count = 1\n",
    "word_ngrams = 3\n",
    "thread = 6\n",
    "\n",
    "best_params = None\n",
    "best_score = 0\n",
    "for dim, lr in combinations:\n",
    "    model = fasttext.supervised(\n",
    "        FASTTEXT_INPUT_FILE, MODEL_PATH, dim=dim, lr=lr, epoch=epoch,\n",
    "        min_count=min_count, word_ngrams=word_ngrams,\n",
    "        thread=thread, label_prefix=label_prefix\n",
    "    )\n",
    "    preds = model.predict([l.text for l in x_test])\n",
    "    preds = [int(pred[0]) for pred in preds]\n",
    "    score = f1_score(y_test, preds, average='micro')\n",
    "    if best_score < score:\n",
    "        best_score = score\n",
    "        best_params = {\"dim\": dim, \"lr\": lr}\n",
    "\n",
    "with open(MODELS_TEST_RESULTS, \"a\") as test_scores_table:\n",
    "        writer = csv.writer(test_scores_table, quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow([\"FT\", best_score, '', str(best_params)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
